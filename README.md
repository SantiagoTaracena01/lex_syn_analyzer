# lex_syn_analyzer

This repository contains a lexical and syntactical analyzer implemented in Python. The analyzer takes as input YALex, YAPar, and test files, and determines if the text in the test file belongs to the language generated by the YALex file and corresponds to the syntactical rules written in the YAPar file. It also provides simulations for both the lexical and syntactical analysis processes.

### Usage
#### Prerequisites
- Python 3.x
- YALex file (for lexical analysis)
- YAPar file (for syntactical analysis)
- Test file (containing the text to be analyzed)

### Setup

Clone this repository to your local machine or download the source code as a ZIP file.
Place the YALex file, YAPar file, and test file in the same directory as the Python scripts.

### Lexical Analysis

In order to execute a lexical analysis over a .txt file, first you have to generate a scanner that recognizes the language of a YALex file. If you want to generate a scanner, execute:

```sh
python generate_scanner.py <yalex-file> <scanner-file>
```

Where `<yalex-file>` is the name of the .yal file that contains the lexical rules that you want to use, and `<scanner-file>` is the name of the .py scanner you want to generate.

After generating the scanner file, you only need to execute it and pass the test file as a parameter. Let's say you generated a scanner named `scanner.py` (which is the default name of it); to use it, you would have to execute:

```sh
python scanner.py <test-file> <output-file> <mode>
```

Where `<test-file>` is a file that contains text that you wanna test, `<output-file>` is a file where the result of the analysis would be, and `<mode>` is a string between `"analysis"` and `"parsing"`, with `"analysis"` meaning that you'd like to get a complete analysis of the text file as an output, and `"parsing"` meaning that you just want to return a file with the token names found in the test file.

### Syntactical Analysis

If you want to execute a syntactical analysis over a .txt file, first you would need to have a test file containing only the token names that you'd like to test. If you want to test a string or a complete file that has not been parsed as tokens, you'd need to also use the lexical analyzer of this project.

With that token file, you can execute the file `generate_parser.py` to get a full syntactical analysis and simulation of the file you passed as a test. To do that analysis, execute:

```sh
python generate_parser.py <yapar-file> <test-file>
```

Where `<yapar-file>` is a YAPar file containing the syntactical rules you wanna test, and `<test-file>` is a .txt file containing tokens defined in that YAPar file. This execution generates tables containing the full simulation as an output, as well as a boolean that is `True` if the test file passed belongs to the rules defined in the YAPar file, and `False` if it doesn't.

License
This project is licensed under the MIT License. See the LICENSE file for more details.

Thank you for using `lex_syn_analyzer`!
